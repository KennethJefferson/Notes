- # [[Terms and Definitions]]
  collapsed:: true
	- **[[Accuracy]]**
		- Percentage of correct predictions made by the model.
	- **[[Algorithm]]**
		- A method, function, or series of instructions used to generate a machine learning model. Examples include linear regression, decision trees, support vector machines, and neural networks.
	- **[[Attribute]]**
		- A quality describing an observation (e.g. color, size, weight). In Excel terms, these are column headers.
	- **[[Bias metric]]**
		- What is the average difference between your predictions and the correct value for that observation?
			- Low bias could mean every prediction is correct. It could also mean half of your predictions are above their actual values and half are below, in equal proportion, resulting in low average difference.
			- High bias (with low variance) suggests your model may be underfitting and you’re using the wrong architecture for the job.
	- **[[Bias term]]**
		- Allow models to represent patterns that do not pass through the origin. For example, if all my features were 0, would my output also be zero? Is it possible there is some base value upon which my features have an effect? Bias terms typically accompany weights and are attached to neurons or filters.
	- **[[Categorical Variables]]**
		- Variables with a discrete set of possible values. Can be ordinal (order matters) or nominal (order doesn’t matter).
	- **[[Classification]]**
		- Predicting a categorical output.
			- Binary classification predicts one of two possible outcomes (e.g. is the email spam or not spam?)
			- Multi-class classification predicts one of multiple possible outcomes (e.g. is this a photo of a cat, dog, horse or human?)
	- **[[Classification Threshold]]**
		- The lowest probability value at which we’re comfortable asserting a positive classification. For example, if the predicted probability of being diabetic is > 50%, return True, otherwise return False.
	- **[[Clustering]]**
		- Unsupervised grouping of data into buckets.
	- **[[Confusion Matrix]]**
		- Table that describes the performance of a classification model by grouping predictions into 4 categories.
			- True Positives: we correctly predicted they do have diabetes
			- True Negatives: we correctly predicted they don’t have diabetes
			- False Positives: we incorrectly predicted they do have diabetes (Type I error)
			- False Negatives: we incorrectly predicted they don’t have diabetes (Type II error)
	- **[[Continuous Variables]]**
		- Variables with a range of possible values defined by a number scale (e.g. sales, lifespan).
	- **[[Convergence]]**
		- A state reached during the training of a model when the loss changes very little between each iteration.
	- **[[Deduction]]**
		- A top-down approach to answering questions or solving problems. A logic technique that starts with a theory and tests that theory with observations to derive a conclusion. E.g. We suspect X, but we need to test our hypothesis before coming to any conclusions.
	- **[[Deep Learning]]**
		- Deep Learning is derived from a machine learning algorithm called perceptron or multi layer perceptron that is gaining more and more attention nowadays because of its success in different fields like, computer vision to signal processing and medical diagnosis to self-driving cars. Like other AI algorithms, deep learning is based on decades of research. Nowadays, we have more and more data and cheap computing power that makes this algorithm really powerful in achieving state of the art accuracy. In modern world this algorithm is known as artificial neural network. Deep learning is much more accurate and robust compared to traditional artificial neural networks. But it is highly influenced by machine learning’s neural network and perceptron networks.
	- **[[Dimension]]**
		- Dimension for machine learning and data scientist is different from physics
	- **[[Epoch]]**
		- An epoch describes the number of times the algorithm sees the entire data set.
	- **[[Extrapolation]]**
		- Making predictions outside the range of a dataset. E.g. My dog barks, so all dogs must bark. In machine learning we often run into trouble when we extrapolate outside the range of our training data.
	- **[[False Positive Rate]]**
		- Defined as FPR=1−Specificity=FalsePositives/(FalsePositives+TrueNegatives). The False Positive Rate forms the x-axis of the ROC curve.
	- **[[Feature]]**
		- With respect to a dataset, a feature represents an attribute and value combination. Color is an attribute. “Color is blue” is a feature. In Excel terms, features are similar to cells. The term feature has other definitions in different contexts.
	- **[[Feature Selection]]**
		- Feature selection is the process of selecting relevant features from a data-set for creating a Machine Learning model.
	- **[[Feature Vector]]**
		- A list of features describing an observation with multiple attributes. In Excel we call this a row.
	- **[[Gradient Accumulation]]**
		- A mechanism to split the batch of samples—used for training a neural network—into several mini-batches of samples that will be run sequentially. This is used to enable using large batch sizes that require more GPU memory than available.
	- **[[Hyperparameters]]**
		- Hyperparameters are higher-level properties of a model such as how fast it can learn (learning rate) or complexity of a model. The depth of trees in a Decision Tree or number of hidden layers in a Neural Networks are examples of hyper parameters.
	- **[[Induction]]**
		- A bottoms-up approach to answering questions or solving problems. A logic technique that goes from observations to theory. E.g. We keep observing X, so we infer that Y must be True.
	- **[[Instance]]**
		- A data point, row, or sample in a dataset. Another term for observation.
	- **[[Label]]**
		- The “answer” portion of an observation in supervised learning. For example, in a dataset used to classify flowers into different species, the features might include the petal length and petal width, while the label would be the flower’s species.
	- **[[Learning Rate]]**
		- The size of the update steps to take during optimization loops like Gradient Descent. With a high learning rate we can cover more ground each step, but we risk overshooting the lowest point since the slope of the hill is constantly changing. With a very low learning rate, we can confidently move in the direction of the negative gradient since we are recalculating it so frequently. A low learning rate is more precise, but calculating the gradient is time-consuming, so it will take us a very long time to get to the bottom.
	- **[[Loss]]**
		- Loss = true_value(from data-set)- predicted value(from ML-model) The lower the loss, the better a model (unless the model has over-fitted to the training data). The loss is calculated on training and validation and its interpretation is how well the model is doing for these two sets. Unlike accuracy, loss is not a percentage. It is a summation of the errors made for each example in training or validation sets.
	- **[[Machine Learning]]**
		- Mitchell (1997) provides a succinct definition: “A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E.” In simple language machine learning is a field in which human made algorithms have an ability learn by itself or predict future for unseen data.
	- **[[Model]]**
		- A data structure that stores a representation of a dataset (weights and biases).
	- **[[Neural Network]]**
		- A Machine Learning model inspired by the human brain that is composed of a large number of highly interconnected processing elements (neurons) working in unison to solve specific problems. Neural networks are particularly effective for predicting events when the network has a large database of prior examples to draw on.
	- **[[Overfitting]]**
		- When a model is trained too long or with too many features, it starts to memorize noise in the training set and perform poorly on unseen data. This is a common problem in machine learning. It's like when a student memorizes the answers for a test instead of understanding the underlying principles. They may pass the test, but fail to generalize the knowledge to other problems.
	- **[[Precision]]**
		- Precision is a measure of the accuracy of a classifier when it predicts the positive class. Precision = True Positives / (True Positives + False Positives). It is the ability of the classifier not to label as positive a sample that is negative.
	- **[[Recall]]**
		- Recall is a measure of a classifier's completeness. Recall = True Positives / (True Positives + False Negatives). It is the ability of the classifier to find all the positive samples.
	- **[[Reinforcement Learning]]**
		- A type of machine learning where an agent learns to make decisions by performing actions to achieve a goal. The agent receives rewards or penalties for its actions and aims to maximize the total reward.
	- **[[Supervised Learning]]**
		- A form of machine learning where the model learns to predict outcomes based on labelled training data. The model makes predictions based on input and then is corrected by comparing the prediction with the desired output.
	- **[[Testing Dataset]]**
		- A subset of the dataset used to assess the performance of the model after the training phase. This set of data is unseen by the model during training and thus provides an unbiased evaluation of the model.
	- **[[Training Dataset]]**
		- A subset of the dataset used to train the model and tune its parameters. The model sees this data during its training phase.
	- **[[Underfitting]]**
		- When a machine learning model is too simple and doesn't capture the complexity of the data, causing it to perform poorly on both training and testing datasets. Underfitting occurs when the model or the algorithm does not fit the data well enough.
	- **[[Validation Dataset]]**
		- A subset of the dataset used to provide an unbiased evaluation of a model fit on the training dataset while tuning model hyperparameters. The validation set is used to avoid overfitting.
	- **[[Vector]]**
		- In the context of machine learning, a vector is an array of numbers. Vectors can be used to represent features of a data point, where each element corresponds to a different feature. For example, a data point with features "height", "weight", and "age" could be represented by the vector [180, 75, 35].
	- **[[Weights]]**
		- Parameters in a model that the learning algorithm adjusts to optimize the prediction accuracy. In a simple linear regression model, these can be thought of as the slope and intercept parameters of the regression line.
	- **[[Zero-shot learning]]**
		- A machine learning scenario where the model needs to correctly make predictions on examples that have not been seen during training and whose classes are not present in the training set. It differs from the usual supervised learning setting, where all classes are known during training.
- [[RegEx]] Notepad++
	- To convert bold titles to bold titles with backlinks:
		- ```python
		  - Search For: ****(.*?)****
		    
		  - Replace With: **[[\1]]**
		  ```
		-