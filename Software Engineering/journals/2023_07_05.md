- # [[Python]] [[Libraries]] for [[Data Science]]
  collapsed:: true
	- [[Numpy]]
	- [[Pandas]]
	- [[Scikit-learn]]
	- [[Matplotlib]]
	- [[Tensorflow]]
- # [[Project Tips]]
  collapsed:: true
	- **5 Questions to ask before a [[Machine Learning]] project**
		- What type of [[generalization]] I want to do?
		- Do I really need [[Machine Learning]] for this?
		- What data I need for this [[generalization]] ?
		- How my [[generalization]] will get consumed?
		- How to ensure my [[generalization]] is working?
- # [[Bird's Eye View]] of [[Data Science]]
  collapsed:: true
	- [[Math]]
		- [[Statistics]]
		- [[Linear Algebra]]
		- [[Calculus]]
	- [[Programming]]
		- [[Python]]
		- [[R]]
		- [[SQL]]
	- [[Visualisation]]
		- [[Tableau]]
		- [[Power BI]]
		- [[Seaborn]]
		- [[Matplotlib]]
	- [[Deploy]]
		- [[AWS]]
		- [[AZURE]]
		- [[GCP]]
	- [[IDE]]
		- [[Jupyter]]
		- [[Colab]]
		- [[R-Studio]]
		- [[Spyder]]
	- [[Machine Learning]]
		- [[Classification]]
		- [[Regression]]
		- [[Reinforcement]]
		- [[Clustering]]
		- [[Deep Learning]]
		- [[NLP]]
	- [[Web Scraping]]
		- [[URLLIB]]
		- [[Beautiful Soup]]
		- [[Scrapy]]
	- [[Data Analysis]]
		- [[EDA]]
		- [[Data Wrangling]]
		- [[Feature Engineering]]
- # [[Bird's Eye View]] of [[Machine Learning]]
  collapsed:: true
	- [[Supervised Learning]]
		- Data with label
			- [[Classification]]
				- [[Logistic Regression]]
				- [[Naive Bayes Classifier]]
				- [[K-nearest Neighbors]]
				- [[Support Vector Machine]] ([[SVM]])
				- Examples:
					- Email spam detection
					- Speech Recognition
			- [[Regression]]
				- [[Linear Regression]]
				- [[Ridge Regression]]
				- [[ordinary least squares regression]]
				- [[Stepwise regression]]
				- Examples
					- Stock market prediction
					- Rainfall prediction
	- [[Unsupervised Learning]]
		- Data without label
			- [[Clustering]]
				- [[K-means]]
				- [[K-median]]
				- [[hierarchical clustering]]
				- [[Expectation Maximization]]
				- Examples
					- Identifying fake news
					- Document analysis
			- [[Association Analysis]]
				- [[Apriori]]
				- [[Eclat]]
				- [[FP-Growth]]
				- Examples
					- Market Basket Analysis
			- [[Dimensionally Reduction]]
				- [[Feature Extraction]]
					- Principal Component Analysis
				- [[Feature Selection]]
					- [[Wrapper]]
					- [[Filter]]
					- [[Embedded Method]]
					- Examples
						- Analysis of written texts and DNA microarray data.
	- [[Reinforcement Learning]]
		- State and function
			- Model-Free
				- [[Q-Learning]]
				- Hybrid
				- [[Policy optimization]]
			- Model-Based
				- Learn the Model
				- Given the Model
			- Examples
				- Multi-agent System
				- Motion Planning
				- Navigation
- # [[Machine Learning]] [[Projects]]
	- ## Customer Segmentation
	  collapsed:: true
		- **Data gathering:**
			- Collect customer data including demographics, purchase history, and browsing behavior.
		- **[[Datapreprocessing]]** :
			- Cleanse and preprocess the data, handling missing values and outliers.
		- **[[Feature Engineering]]** :
			- Extract relevant features from the data that can help in segmenting customers.
		- **Apply [[clustering algorithms]]** (e.g., [[K-means]] , [[hierarchical clustering]] ) to group customers based on similarity.
		- **Evaluate and validate** the segmentation results using metrics like silhouette score or within-cluster sum of squares.
		- **Use** the customer segments to personalize marketing strategies, improve customer targeting, and enhance customer experience.
	- ## Churn Prediction
	  collapsed:: true
		- Data gathering:
			- Gather historical customer data including usage patterns, transaction history, and customer interactions.
		- Data preprocessing:
			- Cleanse and transform the data, ensuring it is in a suitable format for analysis.
		- Feature selection:
			- Identify relevant features that can help predict customer churn.
		- Build and train predictive models (e.g., logistic regression, random forest) to forecast customer churn.
		- Evaluate model performance using metrics like accuracy, precision, recall, and area under the ROC curve.
		- Use the churn prediction model to identify customers at risk of churn and implement proactive retention strategies.
	- ## Demand Forecasting
	  collapsed:: true
		- Data gathering: Collect historical sales data along with relevant factors such as promotions, seasonality, and market trends.
		- Data preprocessing: Clean and transform the data, handling missing values and outliers.
		- Feature engineering: Create additional features like lagged variables, moving averages, or seasonal indicators.
		- Apply time series forecasting techniques (e.g., ARIMA, exponential smoothing) to predict future demand.
		- Validate the forecast accuracy using metrics like mean absolute error (MAE) or root mean squared error (RMSE).
		- Use demand forecasts to optimize inventory management, production planning, and resource allocation.
	- ## Sentiment Analysis
	  collapsed:: true
		- Data gathering: Collect customer feedback data from various sources such as surveys, social media, and customer reviews.
		- Data preprocessing: Cleanse and preprocess the text data, including tokenization, removing stop words, and stemming/lemmatization.
		- Feature extraction: Convert text into numerical representations (e.g., TF-IDF, word embeddings) to enable analysis.
		- Build and train sentiment classification models (e.g., Naive Bayes, support vector machines) to classify sentiment polarity.
		- Evaluate model performance using metrics like accuracy, precision, recall, and F1-score.
		- Analyze sentiment trends and insights to identify areas for improvement and make data-driven business decisions.
	- ## Fraud Detection
	  collapsed:: true
		- Data gathering: Collect transaction data, including features like transaction amount, location, and customer behavior.
		- Data preprocessing:Clean and preprocess the data, handling missing values and outliers.
		- Feature engineering: Create relevant features such as transaction frequency, deviation from normal behavior, or network analysis.
		- Build and train fraud detection models (e.g., anomaly detection algorithms, machine learning classifiers) to identify fraudulent transactions.
		- Evaluate model performance using metrics like precision, recall, and F1-score.
		- Deploy the fraud detection model in real-time to identify and prevent fraudulent activities.
	-
- # [[Data Science]] [[Finance]] [[Projects]]
  collapsed:: true
	- ## Recession Trends Analysis
	  collapsed:: true
		- Aim - As every decline in the GDP growth rate is not a recession, your task is to identify recession and trends in recession over a period of time.
		- Process:
			- Gather historical GDP data
			- Analyze GDP growth rates
			- Define recession based on predefined criteria
			- Identify recession periods
			- Analyze trends and patterns in recession periods
	- ## Credit Scoring and Segmentation
	  collapsed:: true
		- Aim - To calculate credit scores and segment customers based on their credit scores to gain insights into different customer groups.
		- Process:
			- Gather relevant data from multiple sources, including historical credit data and financial statements
			- Clean the data by handling missing values, removing outliers, and ensuring consistency across different variables.
			- Create new features or modify existing ones that capture meaningful information about the borrowers
			- Calculate Credit Scores using appropriate formulas (example FICO)
			- Create Customer Segments based on their credit scores using clustering techniques
	- ## Currency Exchange Rate Forecasting
	  collapsed:: true
		- Aim - To analyze historical exchange rate data and develop a forecasting model to predict future exchange rates. The goal is to help individuals, businesses, and financial institutions make informed decisions about foreign exchange and international trade.
		- Process:
			- Gather historical exchange rate data
			- Explore and analyze the data
			- Choose a forecasting model (e.g. time series, regression)
			- Train the model using the training data
			- Use the trained model to forecast future exchange rates
- # [[SQL]] AI writing [[Tools]]
  collapsed:: true
	- dbsensei
	- SQLgenius
	- Al query
	- Text2sql
	- EZQL
	- SQLGPT
	- tidb
	- MindsDB
	- Al Data Sidekick
	- Mason
	- Avanty
	- Al2sql
	- SQLtoughAl
	- SQL Chat
	- LogicLoop
- # [[Data Analyst]] [[Tools]]
  collapsed:: true
	- **Languages**
		- [[Python]]
		- [[R]]
		- [[SQL]]
	- **Database**
		- [[SQL Server]]
		- [[MySQL]]
		- [[PostgreSQL]]
		- [[Oracle]]
		- [[MongoDB]]
	- **Business Intelligence**
		- [[QlikView]]
		- [[MicroStrategy]]
		- [[Looker]]
		- [[Domo]]
		- [[Google Data Studio]]
	- **Data Analysis**
		- [[Pandas]] - [[Python]]
		- [[NumPy]] - [[Python]]
		- [[dplyr]] - [[R]]
		- [[tidyverse]] - [[R]]
		- [[Excel]]
	- **Data Visualization**
		- [[Tableau]]
		- [[Power BI]]
		- [[ggplot2]] - [[R]]
		- [[matplotlib]] - [[Python]]
		- [[seaborn]] - [[Python]]
	- **Statistical Analysis**
		- [[SAS]]
		- [[SPSS]]
		- [[scikit-learn]] ([[Python]] library)
		- [[caret]] ([[R]] package)
		- [[Jupyter Notebook]]
	- **Data Cleaning and Preprocessing**
		- [[OpenRefine]]
		- [[Trifacta]]
		- [[Data Wrangler]]
	- **Big Data and Distributed Computing**
		- [[Apache Hadoop]]
		- [[Apache Spark]]
		- [[Hive]]
		- [[Pig]]
		- [[Apache Kafka]]
	- **Data Warehousing and Cloud Services**
		- [[Amazon Redshift]]
		- [[Google BigQuery]]
		- [[Snowflake]]
		- [[Microsoft Azure Synapse Analytics]]
		- [[Amazon Web Services (AWS)]]
		- [[Google Cloud Platform (GCP)]]
		- [[Microsoft Azure]]