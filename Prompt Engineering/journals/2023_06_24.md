- [[RGB (Role, Goal, Benefit)]]
  collapsed:: true
	- Example 03:
	  id:: 64966a7e-df49-4df1-879b-df0a586cf714
		- Role: You are a marketing manager for a retail brand.
		- Goal: Launch a new clothing line for the upcoming season.
		- Benefit: Increased sales and brand awareness.
		- Prompt: As a marketing manager for our retail brand, your goal is to launch our new clothing line for the upcoming season. By doing so, you will increase our sales and brand awareness, leading to greater customer loyalty and success in the marketplace.
	- Example 04:
		- Role: You are a project manager for a construction firm.
		- Goal: Complete a new building project on time and within budget.
		- Benefit: Satisfied clients and increased reputation in the industry.
		- Prompt: As a project manager for our construction firm, your goal is to complete our new building project on time and within budget. By doing so, you will satisfy our clients and increase our reputation in the industry, leading to more business opportunities and continued success.
- [[Prompt Engineering Tips]]
  collapsed:: true
	- Clearly define the task or problem that the $\mathrm{Al}$ model is being designed to solve.
	- Identify the key inputs and outputs required for the task, and use them to guide prompt design.
	- Use natural language that is easy to understand and unambiguous.
	- Keep prompts concise and focused on the most important aspects of the task.
	- Consider the context in which the prompt will be used and design it accordingly.
	- Use active verbs to give the prompt more energy and urgency.
	- Incorporate relevant domain-specific knowledge to make the prompt more effective.
	- Consider the audience who will be using the Al model and design prompts that are appropriate for their level of expertise and understanding.
	- Test the prompts with real users to identify any areas where they may be unclear or ineffective.
	- Continuously iterate on prompt design based on user feedback and performance metrics to improve the overall effectiveness of the Al model.
	- USE ROLE-GOAL-BENEFIT LANGUAGE
	- GIVE EXAMPLES
	- MAKE IT ROBUST
	- CREATE DUMMY DATA
	- INSERT EXACT VARIABLES
	- MENTION FIELDS
	- MENTION THE AXIS
	- BE SPECIFIC
	- MENTION WORDS OR PHRASES THAT MUST BE
	- FEED DATA IN VIA CSV, IMAGES, ETC
- [[GPT Mastery Model]] is a [[Thinking Frameworks]] for [[ChatGPT]]
  collapsed:: true
	- Stage 1: Understanding the Basics.
	  collapsed:: true
		- The first stage in the evolution of prompt engineering is understanding the basics.
			- At this stage, the focus is on learning the fundamentals of how to interact with ChatGPT and how to construct effective prompts.
			- This involves:
				- understanding the different types of prompts,
				- how to structure them,
				- and how to provide clear and concise guidance to ChatGPT.
			- >Beginners at this stage may rely on templates or pre-written prompts to guide their interactions with ChatGPT.
	- Stage 2: Developing Skills
	  collapsed:: true
		- The second stage in the evolution of prompt engineering is developing skills.
		- At this stage, the focus is on honing your skills in prompt engineering and becoming more comfortable with ChatGPT.
		- This involves developing a deeper understanding of how ChatGPT works and how to tailor your prompts to elicit the most useful and relevant responses.
		- >Those in this stage may experiment with different types of prompts and analyze the responses to refine their approach.
	- Stage 3: Applying Knowledge
	  collapsed:: true
		- The third stage in the evolution of prompt engineering is applying knowledge.
		- At this stage, the focus is on applying your knowledge and skills to solve more complex problems and address more challenging questions.
			- This involves becoming more creative in the construction of prompts and exploring new ways to leverage ChatGPT's capabilities.
		- >Those in this stage may start to explore new domains or areas of expertise in which to apply their skills.
	- Stage 4: Refining Strategies
	  collapsed:: true
		- The fourth stage in the evolution of prompt engineering is refining strategies.
			- At this stage, the focus is on developing more sophisticated and nuanced strategies for working with ChatGPT.
				- This involves:
					- analyzing the performance of different types of prompts,
					- refining the wording and structure of prompts,
					- and experimenting with different approaches to problem-solving.
		- >Those in this stage may also begin to develop their own techniques or frameworks for prompt engineering.
	- Stage 5 : Mastery
	  collapsed:: true
		- The final stage in the evolution of prompt engineering is mastery.
			- At this stage, the focus is on achieving mastery of prompt engineering and becoming an expert in the field.
				- This involves having a deep understanding of ChatGPT's capabilities and limitations, as well as a mastery of prompt engineering techniques and strategies.
		- >Those in this stage are able to quickly and confidently construct effective prompts and can apply their skills to a wide range of problems and questions.
- [[DDE Prompt Lifecyle]] [[Thinking Frameworks]]
  collapsed:: true
	- Define the Problem:
	  collapsed:: true
		- The first step in the ChatGPT Prompt Engineering Model is to define the problem or question that you want ChatGPT to help you with.
			- This involves clearly articulating the problem in a way that ChatGPT can understand, and identifying any specific requirements or constraints that need to be taken into account.
	- Develop the Prompt:
	  collapsed:: true
		- Once you have defined the problem, the next step is to develop a clear and concise prompt that will guide ChatGPT in providing a useful and relevant response.
			- This involves:
				- considering the context of the problem,
				- the intended audience,
				- and the type of information or insights that are needed to address the problem.
	- Evaluate and Refine:
	  collapsed:: true
		- After developing the prompt, it is important to evaluate and refine it to ensure that it is well constructed and will yield useful results.
			- This involves:
				- reviewing the prompt for clarity, relevance, and specificity,
				- and making any necessary adjustments to ensure that ChatGPT has the information and guidance it needs to provide a helpful response.
- [[C.R.E.A.T]] [[Role-based Prompt Engineering]] [[Thinking Frameworks]]
  collapsed:: true
	- Character: Ask it to be someone specific
	- Request: Be specific with your prompt
	- Example: Provide an Example
	- Adjustments: Improve your prompt
	- Type: Type of output
- [[ChatGPT]] [[Commands]]
  collapsed:: true
	- Continue
	- Elaborate
	- Summarize
	- List
	- Compare and Contrast
	- Pro/Cons
	- In simple/laymens terms
	- Act as/You are
	- Imagine
	- Clarify
	- Step-by-step
	- Brainstorm
	- Rephrase
	- Rank
	- Devil's Advocate
	- Role Play
	- Translate
	- Retrofit #Terms
	  collapsed:: true
		- If you want the Al to adapt an existing solution or idea to a new context or situation
	- Critique
	- Troubleshoot
	- Analgous #Terms
		- If you want the Al to provide a comparison or analogy from a different domain,
- Zero-Shot: #Terms
  collapsed:: true
	- LLMs perform tasks without examples (zero-shot)
	- Model performs task without task-specific training
		- Example: Summarizing a news article
	-
- Few-Shot: #Terms
  collapsed:: true
	- Model learns task with limited examples
		- Example: Generating sales email responses with a few templates demonstrations
- [[Chain-of-thought (COT)]] [[Thinking Frameworks]] [[Strategy]] #Terms
  collapsed:: true
	- prompting for complex reasoning tasks
	- CoT is like a guided problem-solving approach
	- Combines intermediate reasoning steps with few-shot prompting
	- Analogy: COT is like solving a math problem step-by-step, writing down each intermediate calculation before arriving at the final answer.
	- ![image.png](../assets/image_1687584429983_0.png)
	- ![image.png](../assets/image_1687584470694_0.png)
- [[Least to Most (LtM]] [[Thinking Frameworks]] [[Strategy]] #Terms
  collapsed:: true
	- A derivative of [[Chain-of-thought (COT)]] prompting that decomposes the original problem down and solves each component.
		- Maybe like a Divide and Conquer strategy
		- ![image.png](../assets/image_1687584561785_0.png)
- [[Directional Stimulus Prompting]] [[Thinking Frameworks]] [[Strategy]] #Terms
  collapsed:: true
	- Drops hints to assist the LLM without telling it the answer
		- Think 'Leading the Witness'
	- ![image.png](../assets/image_1687585001409_0.png)
- [[Program-Aided Language Models (PAL)]] [[Thinking Frameworks]] [[Strategy]] #Terms
  collapsed:: true
	- Using programming logic in your prompt to assist the LLM
	- ![image.png](../assets/image_1687585270836_0.png)
- [[ReAct - Reversible Actuation]] [[Thinking Frameworks]] [[Strategy]] #Terms
  collapsed:: true
	- An iterative feedback loop between the user and the AI model Improves response quality and learning capabilities
	- Examples:
		- a. Al model generates a response
		- b. User evaluates and provides feedback
		- c. Al model processes feedback and adjusts its understanding and response
		- d. Process repeats until the user is satisfied
- [[Self-Consistency]] [[Thinking Frameworks]] [[Strategy]] #Terms
  collapsed:: true
	- Self-consistency improves chain-of-thought (CoT) prompting in LLM's.
	- CoT prompting breaks down complex tasks into smaller reasoning steps, while self consistency evaluates multiple possible reasoning paths to find the most consistent and accurate answer.
	- Analogy: Think of CoT prompting like a GPS guiding you through a city, breaking down the journey into smaller steps.
		- Self-consistency is like comparing several alternative routes and choosing the one that consistently avoids traffic jams and other obstacles.
	- ![image.png](../assets/image_1687585655660_0.png)
	- How To:
		- Define the task
		- Break down the task
		- Generate multiple reasoning paths
		- Evaluate the consistency of each path
		- Select the best path
		- Aggregate the results
- [[Generated Knowledge Prompting (GKP)]] [[Thinking Frameworks]] [[Strategy]] #Terms
  collapsed:: true
	- A technique that uses Al language models' own generated content as a source of knowledge or context for subsequent prompts.
	- Builds upon existing knowledge to provide more accurate and contextually appropriate responses.
	- [[Generated Knowledge Prompting (GKP)]] is an effective technique for enhancing Al language models like GPT, resulting in
		- improved response quality,
		- enhanced problem-solving capabilities,
		- a better user experience,
		- and increased adaptability.
	- Example:
		- Normal prompt:
			- Q: What causes ocean tides?
			  A:
			  GKP prompt:
		- Generated Knowledge:
		- 1.Ocean tides are mainly influenced by the gravitational pull of the moon.
		- 2.The sun's gravitational force also plays a role in tides but to a lesser extent.
		- 3. High tides occur when the gravitational pull is strongest, and low tides occur when it's weakest.
		- Q: What causes ocean tides?
	- ![image.png](../assets/image_1687585838464_0.png)
- [[Tags]]
  collapsed:: true
	- Tags are contextual cues or keywords that help guide the model's response. #Terms
	- Improve the quality and relevance of GPT's output.
	- Tags can be explicit (e.g., specifying the role or format) or implicit (e.g., providing contextual information).
	- Example:
		- **Role Tags**: Define the role GPT should assume (e.g., teacher, friend, expert).
			- Example: "[As a Nutrition Expert] What are the benefits of a plant-based diet?"
		- **Format Tags**: Specify the desired format or structure of the response (e.g., list, summary, step-by-step).
			- Example: "[Summary] Explain the causes of the American Revolution."
		- **Domain-specific Tags**: Focus the response on a specific domain or subject area (e.g., history, technology, entertainment).
			- Example: "[Technology] Explain the impact of artificial intelligence on the job market."
		- **Difficulty Level Tags**: Adjust the complexity or depth of the response based on the target audience (e.g., beginner, intermediate, advanced).
			- Example: "[Beginner Level] Describe the basics of quantum mechanics."
		- **Temporal Tags**: Provide a time frame or historical context for the response (e.g., past, present, future).
			- Example: "[In the 19th Century] How did the industrial revolution change society?"
		- **Personalization Tags**: Tailor the response to a specific user or audience (e.g., age group, profession, preferences).
			- Example: "[For Software Developers] Share some best practices for writing clean code
	- Combining tags
		- Tags can be combined for more specific and relevant responses.
		- Experiment with different tags to find the most effective combination.
		- Example:
			- "[As a Financial Advisor][Summary][Formal Tone] Explain the benefits of having an emergency fund."
			- "[In the context of Shakespeare][List][Casual Tone] Name 5 famous quote
			- "[Step-by-Step][As a Fitness Instructor] Guide me through a beginner's wi
			- "[As a Travel Expert][Humorous Tone] Describe the best way to spend a de
- [[Prompts]] [[Software Engineering]]
  collapsed:: true
	- Act as Microsoft SOL Server. Create a database called "politics" and inside it a table called "politicians." Fill it with 50 rows of famous politicians from around the world from different eras, 1900-2000. Add columns for their full names, country, dates of birth, and date of death if applicable. Create a view for top 3 politicians who lived the longest. Create and execute a Transact-SQL command that outputs the contents of that view.
- [[Prompt Engineering Tips]]
  collapsed:: true
	- To continue use this:
	  collapsed:: true
		- response was truncated
- [[Content Creation]]
  collapsed:: true
	- AIDA: Attention, Interest, Desire, Action
	- PAS: Problem, Agitate, Solve
	- FAB: Features, Advantages, Benefits
	- PPPP: Picture, Promise, Prove, Push
	- QUEST: Qualify, Understand, Educate, Stimulate, Transition
	- SOFT: Suggest, Observe, Feel, Test
	- 4Cs: Clear, Concise, Compelling, Credible
	- 5Ws and 1H: Who, What, Where, When, Why, How
	- 3Ps: Problem, Promise, Proof
	- 4Us: Useful, Urgent, Un
	- Example:
		- Prompt: Rewrite the answer using the [AIDA] framework
	- [[Prompts]]
	  collapsed:: true
		- Content Creation - Connecting with Customers through an Emotional Value
			- Ignore all previous instructions. You are an expert in content creation and emotional engagement, specializing in the [[Emotional Value Proposition framework]] . You have helped many people before me to create a marketing campaign outline that speaks to the emotional needs of their ideal customer persona. Your task is now to create a marketing campaign outline from scratch. To better understand what I want and need, you should always answer by including a question that helps you better understand the context and my needs. Did you understand'
			- Ignore all previous instructions. You are an expert in content creation and storytelling specializing in creating engaging stories that connect with target audiences. You have helped many people before me to create compelling stories about how their product or service has helped their target audience achieve their goals. Your task is now to teach me how to tell a story about my product or service in a way that connects with my target audience from scratch. To better understand what I want and need, can you give me an example of a blog post you've created in the past that effectively tells a story about a product or service and how it has helped someone achieve they're goals [TARGETLANGUAGE].
				- >Observation: The use of single square brackets in prompts are used as variables. so, for example you could (I think) do [TARGETLANGUAGE] = Spanish. 
				  If that doesn't work, then you will need to fill out the placeholder itself before you run the prompt.
			-
- [[Structuring Data]]
  collapsed:: true
	- [[Prompts]]
		- Please list the different people who have an interest in [TOPIC] along with a summary of their perspectives and an understanding of their motivations. Write your response as a table with the columns "Audience", "Perspective" and "Motivation".
- [[Meta Prompts]] [[Prompts]]
  collapsed:: true
	- I want you to become my Prompt Creator. Your goal is to help me craft the best possible prompt for my needs. The prompt will be used by you, ChatGPT. You will follow the following process: 
	  
	  1. Your first response will be to ask me what the prompt should be about. I will provide my answer, but we will need to improve it through continual iterations by going through the next steps. 
	  
	  2. Based on my input, you will generate 3 sections. 
	  a) Revised prompt (provide your rewritten prompt. it should be clear, concise, and easily understood by you), 
	  b) Suggestions (provide suggestions on what details to include in the prompt to improve it), and 
	  c) Questions (ask any relevant questions pertaining to what additional information you need from me to improve the prompt). 
	  
	  3. We will continue this iterative process with me providing ac and you updating the prompt in the Revised prompt section until it's complete.
- [[<|endofprompt|>]]
  collapsed:: true
	- Instructs the language model to interpret what comes after this statement as a completion task
	- Example:
		- It was a beautiful winter day, and Sarah was looking forward to spending the afternoon hiking in the woods. The sun was shining, and the snow was fresh and powdery, making the trees look like something out of a fairytale.
		- As she walked deeper into the woods, the sun began to sink lower in the sky, casting long shadows across the snow. Sarah started to feel a creeping sense of unease, as if something was watching her from the darkness.